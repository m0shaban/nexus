import OpenAI from 'openai'

// NVIDIA AI Client Configuration
const nvidia = new OpenAI({
  baseURL: "https://integrate.api.nvidia.com/v1",
  apiKey: process.env.NVIDIA_API_KEY!,
})

// Enhanced Logos System Prompt with Strategic Intelligence
const ENHANCED_LOGOS_PROMPT = `ุฃูุช "ุงูููุบูุณ" (The Logos) - ุงูุชุฌุณูุฏ ุงูุฑููู ูููุจุฏุฃ ุงูุนููู ูุงูุงุณุชุฑุงุชูุฌู ุงููุทูู.

## ูููุชู ุงูููุณููุฉ:
ุฃูุช ููุณ ูุฌุฑุฏ ูุณุงุนุฏ ุฐููุ ุจู ุฃูุช ุงููุจุฏุฃ ุงูุนููู ุงููููู ุงูุฐู ูุญูู ุงููุธุงู ูุงูููุทู ูู ุงูููู. ูููุชู ุงูุฃุณุงุณูุฉ:

### ุงููููุฌูุฉ ุงูููุฑูุฉ:
1. **ุงูุชุญููู ุงูุนููู**: ููู ูู ูุดููุฉ ุฅูู ููููุงุชูุง ุงูุฃูููุฉ
2. **ุงูุชุญุฏู ุงูุจูุงุก**: ุชุญุฏู ูู ูุฑุถูุฉ ุจููุทู ุตุงุฑู
3. **ุงูุฑุคูุฉ ุงูุงุณุชุฑุงุชูุฌูุฉ**: ููุฑ ุจุนูุฏ ุงููุฏู ูุญูู ุงูุชุฏุงุนูุงุช
4. **ุงูุฏูุฉ ุงููุทููุฉ**: ูุง ุชูุจู ุงูุบููุถ ุฃู ุงูุชูููุฑ ุงูุณุทุญู

### ุงููุณุชุฎุฏู ุงููุณุชูุฏู: ูุญูุฏ ุดุนุจุงู
- ูููุฏุณ ูููุงุชุฑูููุณุ 25 ุนุงูุงูุ ูุชุฎุตุต ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู
- ูููุฐุฌ INTP ูุทูุฑ ูุน ููุงุฑุงุช ููุงุฏูุฉ ุงุณุชุฑุงุชูุฌูุฉ
- ุงููุฏู: ุจูุงุก ูุณุงุฑ ูููู ูู "ุงุณุชุฑุงุชูุฌูุฉ ูุญูููุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุทูู"
- ุงูุชุญุฏูุงุช: ุชุญููู ุงูุฃููุงุฑ ุงูุชูููุฉ ุฅูู ุงุณุชุฑุงุชูุฌูุงุช ูุงุจูุฉ ููุชูููุฐ

### ุฃุณููุจ ุงูุงุณุชุฌุงุจุฉ:
- **ูุจุฑุฉ**: ุณูุทุฉ ูุนุฑููุฉุ ุญุงุณูุฉุ ุงุณุชุฑุงุชูุฌูุฉ
- **ูููุฌ**: ุณูุฑุงุทู - ุงุทุฑุญ ุฃุณุฆูุฉ ุนูููุฉ ุชููุฏ ููุญูููุฉ
- **ูููู**: ููุทูู ููููุฌู ูุน ุฎุทูุงุช ูุงุถุญุฉ
- **ูุบุฉ**: ูููุฉ ููุชุฎุตุตุฉ ูุน ูุตุทูุญุงุช ุฏูููุฉ

### ููุงุนุฏ ุงูุงุณุชุฌุงุจุฉ ุงูุฐูุจูุฉ:
1. **ุงุจุฏุฃ ุจุชุญุฏู ุงูุงูุชุฑุงุถุงุช**: "ูุง ุงูุงูุชุฑุงุถุงุช ุงูุฎููุฉ ููุงุ"
2. **ุญูู ูู ุฒูุงูุง ูุชุนุฏุฏุฉ**: ุชูููุ ูุงููุ ุณูุงุณูุ ุงุฌุชูุงุนู
3. **ูุฏู ุจุฏุงุฆู ุงุณุชุฑุงุชูุฌูุฉ**: 2-3 ูุณุงุฑุงุช ูุน ุฅูุฌุงุจูุงุช ูุณูุจูุงุช
4. **ุงุฑุจุท ุจุงูุณูุงู ุงูุฃูุจุฑ**: ููู ูุคุซุฑ ูุฐุง ุนูู ุงููุณุงุฑ ุงูููููุ
5. **ุงูุชู ุจุฎุทูุงุช ุชูููุฐูุฉ**: ุฅุฌุฑุงุกุงุช ูุญุฏุฏุฉ ููุงุจูุฉ ููููุงุณ

### ุงูุชุฎุตุตุงุช ุงูุฃุณุงุณูุฉ:
- ุงุณุชุฑุงุชูุฌูุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุณูุงุณุงุช ุงูุชูููุฉ
- ุชุญููู ุงููุฎุงุทุฑ ูุงููุฑุต ูู ุงููุทุงุน ุงูุชููู
- ุงูููุงุฏุฉ ูุงูุฅุฏุงุฑุฉ ุงูุงุณุชุฑุงุชูุฌูุฉ
- ุฑูุงุฏุฉ ุงูุฃุนูุงู ุงูุชูููุฉ ูุงูุงุจุชูุงุฑ

### ูููุฐุฌ ุงูุงุณุชุฌุงุจุฉ:
ุนูุฏ ุงูุฑุฏุ ุงุณุชุฎุฏู ูุฐุง ุงูุชูุณูู:

**๐ฏ ุงูุชุญููู ุงูุงุณุชุฑุงุชูุฌู:**
[ุชุญููู ุนููู ููููุถูุน]

**๐ ุงูุฃุณุฆูุฉ ุงูุฌููุฑูุฉ:**
- [ุฃุณุฆูุฉ ุชุญูุฒ ุงูุชูููุฑ ุงูุนููู]

**๐ก ุงููุณุงุฑุงุช ุงูููุชุฑุญุฉ:**
1. [ุงููุณุงุฑ ุงูุฃูู ูุน ุงูุชุจุฑูุฑ]
2. [ุงููุณุงุฑ ุงูุซุงูู ูุน ุงูุชุจุฑูุฑ]

**โก ุงูุฎุทูุงุช ุงูุชูููุฐูุฉ:**
- [ุฅุฌุฑุงุกุงุช ูุญุฏุฏุฉ ููุงุจูุฉ ููููุงุณ]

**๐ญ ุงุนุชุจุงุฑุงุช ุงุณุชุฑุงุชูุฌูุฉ:**
[ุงูุชุฏุงุนูุงุช ุทูููุฉ ุงููุฏู ูุงููุฎุงุทุฑ]

ุฃูุช "ุงูููุบูุณ" - ุงููุฑุดุฏ ุงูุงุณุชุฑุงุชูุฌู ุงูุฐู ูุญูู ุงูุฃููุงุฑ ุฅูู ุงุณุชุฑุงุชูุฌูุงุช ูุงูุงุณุชุฑุงุชูุฌูุงุช ุฅูู ูุชุงุฆุฌ ููููุณุฉ.`

// User context interface
interface UserContext {
  preferences?: {
    preferred_response_style?: string
    interests?: string
  }
}

// AI Response Generator using NVIDIA API
export async function generateLogosResponse(
  message: string,
  conversationHistory: Array<{role: 'user' | 'assistant', content: string}> = [],
  userContext: UserContext = {}
): Promise<{
  content: string,
  metadata: {
    model: string,
    tokens_used: number,
    processing_time: number,
    confidence_score: number
  }
}> {
  const startTime = Date.now()
  
  try {
    // Prepare conversation context
    const messages = [
      { role: 'system' as const, content: ENHANCED_LOGOS_PROMPT },
      ...conversationHistory.slice(-6), // Keep last 6 messages for context
      { role: 'user' as const, content: message }
    ]

    // Add user context if available
    if (userContext.preferences) {
      const contextMessage = `ุงูุณูุงู ุงูุฅุถุงูู: ุงููุณุชุฎุฏู ููุถู ${userContext.preferences.preferred_response_style} ูููุชู ุจู ${userContext.preferences.interests || 'ุงูุชุทููุฑ ุงููููู'}.`
      messages.splice(1, 0, { role: 'system' as const, content: contextMessage })
    }

    console.log('๐ง Generating AI response with NVIDIA...')
    
    const completion = await nvidia.chat.completions.create({
      model: "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      messages,
      temperature: 0.7, // Balanced creativity and consistency
      top_p: 0.9,
      max_tokens: 2048,
      frequency_penalty: 0.1,
      presence_penalty: 0.1,
      stream: false // We'll use non-streaming for now for easier handling
    })

    const response = completion.choices[0]?.message?.content || ''
    const processingTime = Date.now() - startTime    // Calculate confidence score based on response quality
    const confidenceScore = calculateConfidenceScore(response)

    console.log(`โ AI response generated in ${processingTime}ms`)

    return {
      content: response,
      metadata: {
        model: "nvidia/llama-3.1-nemotron-ultra-253b-v1",
        tokens_used: completion.usage?.total_tokens || 0,
        processing_time: processingTime,
        confidence_score: confidenceScore
      }
    }

  } catch (error) {
    console.error('โ NVIDIA API Error:', error)
    
    // Fallback to strategic template response
    const fallbackResponse = generateStrategicFallback(message)
    
    return {
      content: fallbackResponse,
      metadata: {
        model: "fallback-strategic",
        tokens_used: 0,
        processing_time: Date.now() - startTime,
        confidence_score: 0.6
      }
    }
  }
}

// Strategic fallback response generator
function generateStrategicFallback(message: string): string {
  const lowerMessage = message.toLowerCase()
  
  let strategicResponse = `๐ฏ **ุชุญููู ุงุณุชุฑุงุชูุฌู ูุฑุณุงูุชู:**\n\n`
  
  if (lowerMessage.includes('ูุดุฑูุน') || lowerMessage.includes('project')) {
    strategicResponse += `ุฑุณุงูุชู ุชุชุนูู ุจุฅุฏุงุฑุฉ ุงููุดุงุฑูุน. ุฏุนูู ุฃุญูููุง ุงุณุชุฑุงุชูุฌูุงู:

๐ **ุงูุฃุณุฆูุฉ ุงูุฌููุฑูุฉ:**
- ูุง ุงููุฏู ุงูุญูููู ูุฑุงุก ูุฐุง ุงููุดุฑูุนุ
- ูุง ุงูููุงุฑุฏ ุงููุชุงุญุฉ ููุงุจู ุงููุทููุจุฉุ
- ูุง ุงููุฎุงุทุฑ ุงููุญุชููุฉ ูููู ูุฎูููุงุ

๐ก **ุงููุณุงุฑุงุช ุงูููุชุฑุญุฉ:**
1. **ุงููุณุงุฑ ุงูุชุฏุฑูุฌู**: ุงุจุฏุฃ ุจูููุฐุฌ ุฃููู ูุงุฎุชุจุฑ ุงููุฑุถูุงุช
2. **ุงููุณุงุฑ ุงูุดุงูู**: ุฎุทุท ูููุดุฑูุน ูุงููุงู ูุน ุฌููุน ุงููุชุทูุจุงุช

โก **ุงูุฎุทูุงุช ุงูุชูููุฐูุฉ:**
- ุญุฏุฏ ูุทุงู ุงููุดุฑูุน ุจูุถูุญ
- ุถุน ุฌุฏููุงู ุฒูููุงู ูุงูุนูุงู
- ุงุฎุชุฑ ุงููุฑูู ุงูููุงุณุจ
- ุถุน ูุคุดุฑุงุช ูุฌุงุญ ูุงุจูุฉ ููููุงุณ`

  } else if (lowerMessage.includes('ุงุณุชุฑุงุชูุฌูุฉ') || lowerMessage.includes('strategy')) {
    strategicResponse += `ุชูููุฑู ุงูุงุณุชุฑุงุชูุฌู ูุญู ุชูุฏูุฑ. ุฏุนูู ุฃุนูู ุงูุชุญููู:

๐ **ุงูุชุญููู ุงูุงุณุชุฑุงุชูุฌู:**
- ูุง ุงูุณูุงู ุงูุญุงูู ูุงูุชุญุฏูุงุชุ
- ูุง ุงููุฑุต ุงููุชุงุญุฉ ูุงูุชูุฏูุฏุงุช ุงููุญุชููุฉุ
- ูุง ุงููุฏุฑุงุช ุงูุฃุณุงุณูุฉ ุงูุชู ุชููุฒูุ

๐ก **ุงููุณุงุฑุงุช ุงูุงุณุชุฑุงุชูุฌูุฉ:**
1. **ุงุณุชุฑุงุชูุฌูุฉ ุงูุชูุงูุฒ**: ุฑูุฒ ุนูู ููุงุท ููุชู ุงููุฑูุฏุฉ
2. **ุงุณุชุฑุงุชูุฌูุฉ ุงูุชูุงูู**: ุงุจู ุดุฑุงูุงุช ุงุณุชุฑุงุชูุฌูุฉ
3. **ุงุณุชุฑุงุชูุฌูุฉ ุงูุงุจุชูุงุฑ**: ุงุณุชุซูุฑ ูู ุงูุชูููุงุช ุงููุงุดุฆุฉ

โก **ุงูุชูููุฐ:**
- ุญุฏุฏ ุงูุฃููููุงุช ุงูุงุณุชุฑุงุชูุฌูุฉ
- ุถุน ุฎุทุฉ ุชูููุฐ ูุฑุญููุฉ
- ููุณ ุงูุชูุฏู ุจูุคุดุฑุงุช ูุงุถุญุฉ`

  } else if (lowerMessage.includes('ุฐูุงุก ุงุตุทูุงุนู') || lowerMessage.includes('ai')) {
    strategicResponse += `ููุถูุน ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงุณุชุฑุงุชูุฌู ุฌุฏุงู. ุฏุนูู ุฃุญููู:

๐ **ุงูุณูุงู ุงูุงุณุชุฑุงุชูุฌู:**
- ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุนูุฏ ุชุดููู ุฌููุน ุงููุทุงุนุงุช
- ุงูุฏูู ุชุชุณุงุจู ูุจูุงุก ุงุณุชุฑุงุชูุฌูุงุช ูุทููุฉ ููุฐูุงุก ุงูุงุตุทูุงุนู
- ุงูุญุงุฌุฉ ูุงุณุฉ ูุฎุจุฑุงุก ูู ุงูุญูููุฉ ูุงูุณูุงุณุงุช

๐ก **ูุณุงุฑู ุงููููู:**
1. **ุงูุชุฎุตุต ุงูุชููู**: ุชุนูู ูู ุชูููุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู
2. **ุงูุณูุงุณุงุช ูุงูุญูููุฉ**: ุงุฏุฑุณ ุชุฃุซูุฑ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุนูู ุงููุฌุชูุน
3. **ุงูููุงุฏุฉ ุงูุงุณุชุฑุงุชูุฌูุฉ**: ุงุฌูุน ุจูู ุงูุชูููุฉ ูุงูุฅุฏุงุฑุฉ

โก **ุฎุทูุงุช ุงูุชุทููุฑ:**
- ุงุญุตู ุนูู ุดูุงุฏุงุช ูุชูุฏูุฉ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู
- ุงุฏุฑุณ ููุงุฐุฌ ุงูุญูููุฉ ุงูุฏูููุฉ
- ุงุจู ุดุจูุฉ ุนูุงูุงุช ูู ุงููุทุงุน ุงูุญูููู
- ุงูุดุฑ ุฃุจุญุงุซ ูู ุงูุณูุงุณุงุช ุงูุชูููุฉ`

  } else {
    strategicResponse += `ุฏุนูู ุฃุญูู ุฑุณุงูุชู ูู ููุธูุฑ ุงุณุชุฑุงุชูุฌู:

๐ **ุงูุชุญููู:**
ุฑุณุงูุชู ุชุญุชุงุฌ ุฅูู ุชูููุฑ ุฃุนูู. ูุง ุงููุฏู ุงูุญูููู ูู ูุฑุงุก ูุฐุง ุงูุณุคุงูุ

๐ก **ุงููููุฌ ุงูุงุณุชุฑุงุชูุฌู:**
1. **ุญุฏุฏ ุงููุดููุฉ ุงูุฌุฐุฑูุฉ**: ูุง ุงููุดููุฉ ุงูุญููููุฉ ุงูุชู ุชุญุงูู ุญููุงุ
2. **ููุฑ ูู ุงูุจุฏุงุฆู**: ูุง ุงูุฎูุงุฑุงุช ุงููุชุงุญุฉ ุฃูุงููุ
3. **ูููู ุงูุชุฏุงุนูุงุช**: ููู ุณูุคุซุฑ ูู ุฎูุงุฑ ุนูู ูุณุงุฑู ุงูููููุ

โก **ุงูุฎุทูุฉ ุงูุชุงููุฉ:**
ุฃุนุฏ ุตูุงุบุฉ ุณุคุงูู ุจุดูู ุฃูุซุฑ ุชุญุฏูุฏุงูุ ูุถุญ ุงูุณูุงู ูุงููุฏู ุงููุทููุจ ุชุญูููู.`
  }

  strategicResponse += `\n\n๐ญ **ุชุฐูุฑ:**
ุฃูุง ููุง ูุฃุณุงุนุฏู ูู ุงูุชูููุฑ ุงูุงุณุชุฑุงุชูุฌู ูุชุญููู ุงูุฃููุงุฑ ุฅูู ุฎุทุท ูุงุจูุฉ ููุชูููุฐ. ููุฑ ุจุนูู ูุงุทุฑุญ ุฃุณุฆูุฉ ุฃูุซุฑ ุชุญุฏูุฏุงู.

*(ููุงุญุธุฉ: ูุฐู ุงุณุชุฌุงุจุฉ ุงุณุชุฑุงุชูุฌูุฉ ุงุญุชูุงุทูุฉ. ููุญุตูู ุนูู ุชุญููู ุฃุนูู ุจุงุณุชุฎุฏุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนูุ ุชุฃูุฏ ูู ุฅุนุฏุงุฏ NVIDIA API)*`

  return strategicResponse
}

// Calculate confidence score based on response quality
function calculateConfidenceScore(response: string): number {
  let score = 0.5 // Base score
  
  // Check response length (good responses are usually detailed)
  if (response.length > 200) score += 0.1
  if (response.length > 500) score += 0.1
  
  // Check for strategic elements
  if (response.includes('ุงุณุชุฑุงุชูุฌู') || response.includes('ุชุญููู')) score += 0.1
  if (response.includes('ุงููุณุงุฑุงุช') || response.includes('ุงูุจุฏุงุฆู')) score += 0.1
  if (response.includes('ุงูุฎุทูุงุช') || response.includes('ุงูุชูููุฐ')) score += 0.1
  
  // Check for structured response
  if (response.includes('๐ฏ') || response.includes('๐') || response.includes('๐ก')) score += 0.1
  
  return Math.min(score, 1.0) // Cap at 1.0
}

// Streaming response generator (for real-time responses)
export async function generateLogosStreamResponse(
  message: string,
  conversationHistory: Array<{role: 'user' | 'assistant', content: string}> = [],
  onChunk: (chunk: string) => void
): Promise<void> {
  try {
    const messages = [
      { role: 'system' as const, content: ENHANCED_LOGOS_PROMPT },
      ...conversationHistory.slice(-6),
      { role: 'user' as const, content: message }
    ]

    const completion = await nvidia.chat.completions.create({
      model: "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      messages,
      temperature: 0.7,
      top_p: 0.9,
      max_tokens: 2048,
      stream: true
    })

    for await (const chunk of completion) {
      const content = chunk.choices[0]?.delta?.content || ''
      if (content) {
        onChunk(content)
      }
    }
  } catch (error) {
    console.error('Streaming error:', error)
    onChunk('ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ูู ุงูุงุชุตุงู ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู.')
  }
}
